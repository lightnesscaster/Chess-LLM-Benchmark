# Chess LLM Benchmark Configuration
# Models below 400 rating + gpt-5.1-chat

# Benchmark settings
benchmark:
  games_vs_anchor_per_color: 0    # Skip anchor games
  games_vs_llm_per_color: 3       # ~5-6 games per LLM pair (3 as each color)
  max_moves: 200                   # Maximum half-moves per game
  max_concurrent: 30               # Maximum concurrent games

# Engine anchors (fixed ratings)
engines:
  - player_id: "random-bot"
    type: random
    rating: 400

  - player_id: "maia-1100"
    type: maia
    lc0_path: "/opt/homebrew/bin/lc0"
    weights_path: "/Volumes/MainStorage/Programming/create_chess_puzzles/maia-1100.pb"
    rating: 1628
    nodes: 1

  - player_id: "maia-1900"
    type: maia
    lc0_path: "/opt/homebrew/bin/lc0"
    weights_path: "/Volumes/MainStorage/Programming/chess_llm_benchmark/maia-1900.pb.gz"
    rating: 1816
    nodes: 1

  - player_id: "eubos"
    type: uci
    path: "/Volumes/MainStorage/Programming/EubosChess/eubos.sh"
    rating: 2211
    initial_time: 900
    increment: 10

# LLM players - all models below 400 rating + gpt-5.1-chat
llms:
  # gpt-5.1-chat (827) - included by request
  - player_id: "gpt-5.1-chat"
    model_name: "openai/gpt-5.1-chat"
    temperature: 0.0

  # gpt-5-chat (228)
  - player_id: "gpt-5-chat"
    model_name: "openai/gpt-5-chat"
    temperature: 0.0

  # gemini-2.5-flash (no thinking) (223)
  - player_id: "gemini-2.5-flash (no thinking)"
    model_name: "google/gemini-2.5-flash"
    temperature: 0.0

  # gpt-4o-2024-11-20 (186)
  - player_id: "gpt-4o-2024-11-20"
    model_name: "openai/gpt-4o-2024-11-20"
    temperature: 0.0

  # gemini-2.0-flash-001 (180)
  - player_id: "gemini-2.0-flash-001"
    model_name: "google/gemini-2.0-flash-001"
    temperature: 0.0

  # gpt-4.1 (minimal) (170)
  - player_id: "gpt-4.1 (minimal)"
    model_name: "openai/gpt-4.1"
    temperature: 0.0
    reasoning_effort: minimal

  # gpt-5 (minimal) (157)
  - player_id: "gpt-5 (minimal)"
    model_name: "openai/gpt-5"
    temperature: 0.0
    reasoning_effort: minimal

  # claude-opus-4 (no thinking) (143)
  - player_id: "claude-opus-4 (no thinking)"
    model_name: "anthropic/claude-opus-4"
    temperature: 0.0

  # claude-opus-4.1 (no thinking) (59)
  - player_id: "claude-opus-4.1 (no thinking)"
    model_name: "anthropic/claude-opus-4.1"
    temperature: 0.0

  # gpt-4 (16)
  - player_id: "gpt-4"
    model_name: "openai/gpt-4"
    temperature: 0.0

  # claude-3.5-sonnet (12)
  - player_id: "claude-3.5-sonnet"
    model_name: "anthropic/claude-3.5-sonnet"
    temperature: 0.0

  # claude-3.7-sonnet (no thinking) (-60)
  - player_id: "claude-3.7-sonnet (no thinking)"
    model_name: "anthropic/claude-3.7-sonnet"
    temperature: 0.0

  # qwen3-max (-62)
  - player_id: "qwen3-max"
    model_name: "qwen/qwen3-max"
    temperature: 0.0

  # glm-4.6 (no thinking) (-62)
  - player_id: "glm-4.6 (no thinking)"
    model_name: "z-ai/glm-4.6"
    temperature: 0.0

  # deepseek-v3.2-exp (no thinking) (-107)
  - player_id: "deepseek-v3.2-exp (no thinking)"
    model_name: "deepseek/deepseek-v3.2-exp"
    temperature: 0.0

  # claude-sonnet-4 (no thinking) (-164)
  - player_id: "claude-sonnet-4 (no thinking)"
    model_name: "anthropic/claude-sonnet-4"
    temperature: 0.0

  # claude-sonnet-4.5 (no thinking) (-165)
  - player_id: "claude-sonnet-4.5 (no thinking)"
    model_name: "anthropic/claude-sonnet-4.5"
    temperature: 0.0

  # grok-3 (-240)
  - player_id: "grok-3"
    model_name: "x-ai/grok-3"
    temperature: 0.0

  # kimi-k2-0905 (-240)
  - player_id: "kimi-k2-0905"
    model_name: "moonshotai/kimi-k2-0905"
    temperature: 0.0

  # deepseek-v3.1-terminus (no thinking) (-350)
  - player_id: "deepseek-v3.1-terminus (no thinking)"
    model_name: "deepseek/deepseek-chat-v3.1-terminus"
    temperature: 0.0

  # kimi-k2 (-388)
  - player_id: "kimi-k2"
    model_name: "moonshotai/kimi-k2"
    temperature: 0.0

  # qwen3-235b-a22b-2507 (-453)
  - player_id: "qwen3-235b-a22b-2507"
    model_name: "qwen/qwen3-235b-a22b-2507"
    temperature: 0.0

  # gpt-4-turbo (-453)
  - player_id: "gpt-4-turbo"
    model_name: "openai/gpt-4-turbo"
    temperature: 0.0

  # claude-3-opus (-453)
  - player_id: "claude-3-opus"
    model_name: "anthropic/claude-3-opus"
    temperature: 0.0

  # deepseek-chat-v3-0324 (-453)
  - player_id: "deepseek-chat-v3-0324"
    model_name: "deepseek/deepseek-chat-v3-0324"
    temperature: 0.0

  # mistral-medium-3 (-453)
  - player_id: "mistral-medium-3"
    model_name: "mistralai/mistral-medium-3"
    temperature: 0.0

  # claude-haiku-4.5 (no thinking) (-453)
  - player_id: "claude-haiku-4.5 (no thinking)"
    model_name: "anthropic/claude-4.5-haiku"
    temperature: 0.0

  # gpt-3.5-turbo-0613 (-453)
  - player_id: "gpt-3.5-turbo-0613"
    model_name: "openai/gpt-3.5-turbo-0613"
    temperature: 0.0

  # deepseek-chat-v3.1 (no thinking) (-453)
  - player_id: "deepseek-chat-v3.1 (no thinking)"
    model_name: "deepseek/deepseek-chat-v3.1"
    temperature: 0.0

  # gpt-5-mini (minimal) (-453)
  - player_id: "gpt-5-mini (minimal)"
    model_name: "openai/gpt-5-mini"
    temperature: 0.0
    reasoning_effort: minimal

  # llama-3.3-70b-instruct (-453)
  - player_id: "llama-3.3-70b-instruct"
    model_name: "meta-llama/llama-3.3-70b-instruct"
    temperature: 0.0

  # gpt-3.5-turbo (-624)
  - player_id: "gpt-3.5-turbo"
    model_name: "openai/gpt-3.5-turbo"
    temperature: 0.0

  # llama-4-maverick (-704)
  - player_id: "llama-4-maverick"
    model_name: "meta-llama/llama-4-maverick"
    temperature: 0.0
