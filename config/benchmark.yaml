# Chess LLM Benchmark Configuration
# Models below 400 rating + gpt-5.1-chat

# Benchmark settings
benchmark:
  games_vs_anchor_per_color: 0    # Skip anchor games
  games_vs_llm_per_color: 3       # ~5-6 games per LLM pair (3 as each color)
  max_moves: 200                   # Maximum half-moves per game
  max_concurrent: 30               # Maximum concurrent games

# Engine anchors (not used for this benchmark)
engines: []

# LLM players - all models below 400 rating + gpt-5.1-chat
llms:
  # gpt-5.1-chat (827) - included by request
  - player_id: "gpt-5.1-chat"
    model_name: "openai/gpt-5.1-chat"
    temperature: 0.0
    max_tokens: 20

  # gpt-5-chat (228)
  - player_id: "gpt-5-chat"
    model_name: "openai/gpt-5-chat"
    temperature: 0.0
    max_tokens: 20

  # gemini-2.5-flash (no thinking) (223)
  - player_id: "gemini-2.5-flash (no thinking)"
    model_name: "google/gemini-2.5-flash"
    temperature: 0.0
    max_tokens: 20

  # gpt-4o-2024-11-20 (186)
  - player_id: "gpt-4o-2024-11-20"
    model_name: "openai/gpt-4o-2024-11-20"
    temperature: 0.0
    max_tokens: 20

  # gemini-2.0-flash-001 (180)
  - player_id: "gemini-2.0-flash-001"
    model_name: "google/gemini-2.0-flash-001"
    temperature: 0.0
    max_tokens: 20

  # gpt-4.1 (minimal) (170)
  - player_id: "gpt-4.1 (minimal)"
    model_name: "openai/gpt-4.1"
    temperature: 0.0
    max_tokens: 0
    reasoning_effort: minimal

  # gpt-5 (minimal) (157)
  - player_id: "gpt-5 (minimal)"
    model_name: "openai/gpt-5"
    temperature: 0.0
    max_tokens: 0
    reasoning_effort: minimal

  # claude-opus-4 (no thinking) (143)
  - player_id: "claude-opus-4 (no thinking)"
    model_name: "anthropic/claude-opus-4"
    temperature: 0.0
    max_tokens: 20

  # claude-opus-4.1 (no thinking) (59)
  - player_id: "claude-opus-4.1 (no thinking)"
    model_name: "anthropic/claude-opus-4.1"
    temperature: 0.0
    max_tokens: 20

  # gpt-4 (16)
  - player_id: "gpt-4"
    model_name: "openai/gpt-4"
    temperature: 0.0
    max_tokens: 20

  # claude-3.5-sonnet (12)
  - player_id: "claude-3.5-sonnet"
    model_name: "anthropic/claude-3.5-sonnet"
    temperature: 0.0
    max_tokens: 20

  # claude-3.7-sonnet (no thinking) (-60)
  - player_id: "claude-3.7-sonnet (no thinking)"
    model_name: "anthropic/claude-3.7-sonnet"
    temperature: 0.0
    max_tokens: 20

  # qwen3-max (-62)
  - player_id: "qwen3-max"
    model_name: "qwen/qwen3-max"
    temperature: 0.0
    max_tokens: 20

  # deepseek-v3.2-exp (no thinking) (-107)
  - player_id: "deepseek-v3.2-exp (no thinking)"
    model_name: "deepseek/deepseek-v3.2-exp"
    temperature: 0.0
    max_tokens: 20

  # claude-sonnet-4 (no thinking) (-164)
  - player_id: "claude-sonnet-4 (no thinking)"
    model_name: "anthropic/claude-sonnet-4"
    temperature: 0.0
    max_tokens: 20

  # claude-sonnet-4.5 (no thinking) (-165)
  - player_id: "claude-sonnet-4.5 (no thinking)"
    model_name: "anthropic/claude-sonnet-4.5"
    temperature: 0.0
    max_tokens: 20

  # grok-3 (-240)
  - player_id: "grok-3"
    model_name: "x-ai/grok-3"
    temperature: 0.0
    max_tokens: 20

  # kimi-k2-0905 (-240)
  - player_id: "kimi-k2-0905"
    model_name: "moonshotai/kimi-k2-0905"
    temperature: 0.0
    max_tokens: 20

  # deepseek-v3.1-terminus (no thinking) (-350)
  - player_id: "deepseek-v3.1-terminus (no thinking)"
    model_name: "deepseek/deepseek-chat-v3.1-terminus"
    temperature: 0.0
    max_tokens: 20

  # kimi-k2 (-388)
  - player_id: "kimi-k2"
    model_name: "moonshotai/kimi-k2"
    temperature: 0.0
    max_tokens: 20

  # qwen3-235b-a22b-2507 (-453)
  - player_id: "qwen3-235b-a22b-2507"
    model_name: "qwen/qwen3-235b-a22b-2507"
    temperature: 0.0
    max_tokens: 20

  # gpt-4-turbo (-453)
  - player_id: "gpt-4-turbo"
    model_name: "openai/gpt-4-turbo"
    temperature: 0.0
    max_tokens: 20

  # claude-3-opus (-453)
  - player_id: "claude-3-opus"
    model_name: "anthropic/claude-3-opus"
    temperature: 0.0
    max_tokens: 20

  # deepseek-chat-v3-0324 (-453)
  - player_id: "deepseek-chat-v3-0324"
    model_name: "deepseek/deepseek-chat-v3-0324"
    temperature: 0.0
    max_tokens: 20

  # mistral-medium-3 (-453)
  - player_id: "mistral-medium-3"
    model_name: "mistralai/mistral-medium-3"
    temperature: 0.0
    max_tokens: 20

  # claude-haiku-4.5 (no thinking) (-453)
  - player_id: "claude-haiku-4.5 (no thinking)"
    model_name: "anthropic/claude-4.5-haiku"
    temperature: 0.0
    max_tokens: 20

  # gpt-3.5-turbo-0613 (-453)
  - player_id: "gpt-3.5-turbo-0613"
    model_name: "openai/gpt-3.5-turbo-0613"
    temperature: 0.0
    max_tokens: 20

  # deepseek-chat-v3.1 (no thinking) (-453)
  - player_id: "deepseek-chat-v3.1 (no thinking)"
    model_name: "deepseek/deepseek-chat-v3.1"
    temperature: 0.0
    max_tokens: 20

  # gpt-5-mini (minimal) (-453)
  - player_id: "gpt-5-mini (minimal)"
    model_name: "openai/gpt-5-mini"
    temperature: 0.0
    max_tokens: 0
    reasoning_effort: minimal

  # llama-3.3-70b-instruct (-453)
  - player_id: "llama-3.3-70b-instruct"
    model_name: "meta-llama/llama-3.3-70b-instruct"
    temperature: 0.0
    max_tokens: 20

  # gpt-3.5-turbo (-624)
  - player_id: "gpt-3.5-turbo"
    model_name: "openai/gpt-3.5-turbo"
    temperature: 0.0
    max_tokens: 20

  # llama-4-maverick (-704)
  - player_id: "llama-4-maverick"
    model_name: "meta-llama/llama-4-maverick"
    temperature: 0.0
    max_tokens: 20
